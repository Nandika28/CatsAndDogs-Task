{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task2-with-vgg16.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nandika28/CatsAndDogs-Task/blob/master/Task2_with_vgg16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMJ6877yO1dR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import glob\n",
        "\n",
        "# Helper libraries\n",
        "import IPython.display as display\n",
        "from PIL import Image\n",
        "from matplotlib.image import imread\n",
        "import os.path\n",
        "from os import path\n",
        "import matplotlib.cm as cm\n",
        "import sys\n",
        "import datetime\n",
        "import glob as glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "import keras\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from keras.optimizers import SGD\n",
        "#from scipy.interpolate import spline\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CjRPL3FDDTB",
        "colab_type": "text"
      },
      "source": [
        "Step 1: Download the Dataset and get familiar with the organization of data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EIQRYL3rrtt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "20e8dfa7-3501-4041-8e54-408f5d5a2523"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip \\\n",
        "-O \"/tmp/cats-and-dogs.zip\"\n",
        "\n",
        "import zipfile\n",
        "zipped_data_path = \"/tmp/cats-and-dogs.zip\"\n",
        "zip_ref = zipfile.ZipFile(zipped_data_path,'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-11 08:20:28--  https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n",
            "Resolving download.microsoft.com (download.microsoft.com)... 23.193.24.126, 2600:140e:6:b8d::e59, 2600:140e:6:ba1::e59\n",
            "Connecting to download.microsoft.com (download.microsoft.com)|23.193.24.126|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 824894548 (787M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/cats-and-dogs.zip’\n",
            "\n",
            "\r/tmp/cats-and-dogs.   0%[                    ]       0  --.-KB/s               \r/tmp/cats-and-dogs.   8%[>                   ]  66.15M   331MB/s               \r/tmp/cats-and-dogs.  16%[==>                 ] 130.76M   327MB/s               \r/tmp/cats-and-dogs.  25%[====>               ] 199.90M   333MB/s               \r/tmp/cats-and-dogs.  33%[=====>              ] 260.84M   326MB/s               \r/tmp/cats-and-dogs.  39%[======>             ] 310.15M   310MB/s               \r/tmp/cats-and-dogs.  46%[========>           ] 364.65M   304MB/s               \r/tmp/cats-and-dogs.  54%[=========>          ] 429.92M   307MB/s               \r/tmp/cats-and-dogs.  62%[===========>        ] 494.60M   309MB/s               \r/tmp/cats-and-dogs.  71%[=============>      ] 559.59M   311MB/s               \r/tmp/cats-and-dogs.  79%[==============>     ] 622.31M   311MB/s               \r/tmp/cats-and-dogs.  88%[================>   ] 692.52M   315MB/s               \r/tmp/cats-and-dogs.  96%[==================> ] 762.71M   318MB/s               \r/tmp/cats-and-dogs. 100%[===================>] 786.68M   319MB/s    in 2.5s    \n",
            "\n",
            "2020-07-11 08:20:31 (319 MB/s) - ‘/tmp/cats-and-dogs.zip’ saved [824894548/824894548]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XusFKMlRDIa0",
        "colab_type": "text"
      },
      "source": [
        "Step 2: Plan how you will prepare the data to feed to your data processor. (E.g. Maybe you want\n",
        "to create a new csv or excel file with all the necessary information or feed the current structure\n",
        "itself to the data processor)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZ5eUn6nQspk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9f7a1c0-3948-4c33-d03c-85f781681e6a"
      },
      "source": [
        "data_dir = '/tmp/PetImages/'\n",
        "CLASS_NAMES = os.listdir(data_dir)\n",
        "print(CLASS_NAMES)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Cat', 'Dog']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4vK3XHfs3aY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "cat_files=os.listdir(\"/tmp/PetImages/Cat/\")\n",
        "\n",
        "dog_files=os.listdir(\"/tmp/PetImages/Dog/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ICbCV6DtgWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_train, cat_test = train_test_split(cat_files, test_size = 0.2, random_state = 5)\n",
        "dog_train, dog_test = train_test_split(dog_files, test_size = 0.2, random_state = 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJzKtUSFtiq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file_names = cat_train + dog_train \n",
        "\n",
        "test_file_names = cat_test + dog_test "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5nv--8dtlPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.shuffle(train_file_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-2Lyh24tpYL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "3519e963-0070-40f8-8b3d-c3b7dc88400f"
      },
      "source": [
        "print(\"Number of train_files:\" ,len(train_file_names))\n",
        "\n",
        "print(\"Number of test_files:\" ,len(test_file_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of train_files: 20000\n",
            "Number of test_files: 5002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVGakpO8tr02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.mkdir(\"./random_dir\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHfLAzDHDfz4",
        "colab_type": "text"
      },
      "source": [
        "Step 3: Create data processors for Training and Testing/Validation. There are many ways to\n",
        "handle data - Keras Sequences, Keras Generators, TF.Data Pipelines. (Rule of Thumb: Never\n",
        "show testing/validation data to your model while training).\n",
        "1. In Task 1 Step 3, use image augmentation with your data processors.-----Here datagenerator is used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sKukzXUuG60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.mkdir(\"./random_dir/train\")\n",
        "os.mkdir(\"./random_dir/test\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENuluFtLuJko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for class_name in CLASS_NAMES:\n",
        "  os.mkdir(os.path.join(\"./random_dir/train\", class_name))\n",
        "  os.mkdir(os.path.join(\"./random_dir/test\", class_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUva2vOmurQc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b468f1df-0231-4b54-9f47-a4f1152a81d6"
      },
      "source": [
        "import shutil\n",
        "from os import listdir\n",
        "from PIL import Image\n",
        "for file in cat_train:\n",
        "  if(file!='Thumbs.db' ):\n",
        "    path_file=os.path.join(os.path.join(data_dir,\"Cat\"),file)\n",
        "    if(path.exists(path_file) ):\n",
        "      try:\n",
        "        img = Image.open(path_file) # open the image file\n",
        "        img.verify() # verify that it is, in fact an image\n",
        "        dest=(\"./random_dir/train/Cat/\"+file)\n",
        "        shutil.copyfile(path_file, dest)\n",
        "      except (IOError, SyntaxError) as e:   \n",
        "        print('Bad file:', file) # print out the names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bad file: 666.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTZ-N72cuMK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "from os import listdir\n",
        "from PIL import Image\n",
        "for file in cat_test:\n",
        "  if(file!='Thumbs.db' ):\n",
        "    path_file=os.path.join(os.path.join(data_dir,\"Cat\"),file)\n",
        "    if(path.exists(path_file) ):\n",
        "      try:\n",
        "        img = Image.open(path_file) # open the image file\n",
        "        img.verify() # verify that it is, in fact an image\n",
        "        dest=(\"./random_dir/test/Cat/\"+file)\n",
        "        shutil.copyfile(path_file, dest)\n",
        "      except (IOError, SyntaxError) as e:\n",
        "        print('Bad file:', file) # print out the names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4k1bhSoyfc5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "outputId": "99c5df20-1f35-41b3-bd80-214fa6be461b"
      },
      "source": [
        "import warnings\n",
        "for file in dog_train:\n",
        "  if(file!='Thumbs.db' ):\n",
        "    path_file=os.path.join(os.path.join(data_dir,\"Dog\"),file)\n",
        "    if(path.exists(path_file) ):\n",
        "      try:\n",
        "        img = Image.open(path_file) # open the image file\n",
        "        img.verify() # verify that it is, in fact an image\n",
        "        dest=(\"./random_dir/train/Dog/\"+file)\n",
        "        shutil.copyfile(path_file, dest)\n",
        "      except (IOError, SyntaxError) as e:\n",
        "        print('Bad file:', file) # print out the name\n",
        "        warnings.filterwarnings('always')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bad file: 11702.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 32 bytes but only got 0. Skipping tag 270\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5 bytes but only got 0. Skipping tag 271\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 272\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 48 bytes but only got 0. Skipping tag 532\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwEFZuh2zHbC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for file in dog_test:\n",
        "  if(file!='Thumbs.db' ):\n",
        "    path_file=os.path.join(os.path.join(data_dir,\"Dog\"),file)\n",
        "    if(path.exists(path_file) ):\n",
        "      try:\n",
        "        img = Image.open(path_file) # open the image file\n",
        "        img.verify() # verify that it is, in fact an image\n",
        "        dest=(\"./random_dir/test/Dog/\"+file)\n",
        "        shutil.copyfile(path_file, dest)\n",
        "      except (IOError, SyntaxError) as e:\n",
        "        print('Bad file:', file) # print out the names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtimyceRDWQP",
        "colab_type": "text"
      },
      "source": [
        "Step 4: Create your own Neural network with Convolution layers, Max Pool Layers, Dense Layers,\n",
        "Dropout layers from scratch \n",
        "2. In Task 1 Step 4, use known networks (such as VGG16, Resnet, etc.) to train your AI\n",
        "model.----Here keras.applications.xception.Xception has been used for predictions and generation of heat maps "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nUnEDWnJKh9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.mkdir(\"./preview\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-PrM2dmGZW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n",
        "\n",
        "img = load_img('/content/random_dir/train/Cat/10.jpg')  # this is a PIL image\n",
        "x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
        "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
        "\n",
        "# the .flow() command below generates batches of randomly transformed images\n",
        "# and saves the results to the `preview/` directory\n",
        "i = 0\n",
        "for batch in datagen.flow(x, batch_size=1,\n",
        "                          save_to_dir='preview', save_prefix='cat', save_format='jpg'):\n",
        "    i += 1\n",
        "    if i > 20:\n",
        "        break  # otherwise the generator would loop indefinitely"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmT8C1SeGb9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M2zlu4JKC7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data pre-processing for training\n",
        "train_datagen =  ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    rotation_range = 20,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    fill_mode = 'nearest',\n",
        "    horizontal_flip = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdJgDYPJKHYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data pre-processing for validation\n",
        "validate_datagen =  ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    rotation_range = 20,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    fill_mode = 'nearest',\n",
        "    horizontal_flip = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYi3tGlUKRKc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b7748bb9-5353-423f-eab4-fc4fe493ec08"
      },
      "source": [
        "# default settings\n",
        "img_width, img_height = 299, 299\n",
        "# generate and store training data\n",
        "train_dir=\"/content/random_dir/train\"\n",
        "test_dir=\"/content/random_dir/test\"\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size = (img_width, img_height),\n",
        "    batch_size = 1)\n",
        "# generate and store validation data\n",
        "validate_generator = validate_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size = (img_width, img_height),\n",
        "    batch_size = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 19996 images belonging to 2 classes.\n",
            "Found 5002 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiWDEqU8LH64",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "fc2ee0b3-6eae-477c-9115-5198b74d2985"
      },
      "source": [
        "# this will copy the pretrained weights to our kernel\n",
        "!mkdir ~/.keras\n",
        "!mkdir ~/.keras/models\n",
        "!cp ../input/keras-pretrained-models/*notop* ~/.keras/models/\n",
        "!cp ../input/keras-pretrained-models/imagenet_class_index.json ~/.keras/models/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/.keras’: File exists\n",
            "mkdir: cannot create directory ‘/root/.keras/models’: File exists\n",
            "cp: cannot stat '../input/keras-pretrained-models/*notop*': No such file or directory\n",
            "cp: cannot stat '../input/keras-pretrained-models/imagenet_class_index.json': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFd6iZjpLX9D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "badd0f4c-5c9f-4ecf-e27d-80b2d1a2aabe"
      },
      "source": [
        "# set up transfer learning on pre-trained ImageNet VGG16 model - remove fully connected layer and replace\n",
        "# with softmax for classifying 10 classes\n",
        "nb_classes=2\n",
        "vgg16_model = VGG16(weights = 'imagenet', include_top = False)\n",
        "x = vgg16_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(nb_classes, activation = 'softmax')(x)\n",
        "model = Model(input = vgg16_model.input, output = predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUj6h5hsMmSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# freeze all layers of the pre-trained model\n",
        "for layer in vgg16_model.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Nn4PHBMMxdx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile the new model using a RMSProp optimizer\n",
        "model.compile(optimizer = 'rmsprop',\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCxoEgm5M6id",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "outputId": "824174d3-3c52-459d-b168-b168e753765d"
      },
      "source": [
        "transfer_learning_history = model.fit_generator(\n",
        "    train_generator,\n",
        "    nb_epoch = 2,\n",
        "    samples_per_epoch = 19996,\n",
        "    validation_data = validate_generator,\n",
        "    nb_val_samples = 5002,\n",
        "    class_weight='auto')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_data=<keras.pre..., class_weight=\"auto\", steps_per_epoch=19996, epochs=2, validation_steps=5002)`\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "15990/19996 [======================>.......] - ETA: 1:37 - loss: 0.3710 - accuracy: 0.8522"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 32 bytes but only got 0. Skipping tag 270\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5 bytes but only got 0. Skipping tag 271\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 272\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 48 bytes but only got 0. Skipping tag 532\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "19996/19996 [==============================] - 598s 30ms/step - loss: 0.3650 - accuracy: 0.8573 - val_loss: 0.0031 - val_accuracy: 0.9074\n",
            "Epoch 2/2\n",
            "15306/19996 [=====================>........] - ETA: 1:49 - loss: 0.3182 - accuracy: 0.8846"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 32 bytes but only got 0. Skipping tag 270\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5 bytes but only got 0. Skipping tag 271\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 272\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 48 bytes but only got 0. Skipping tag 532\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "19996/19996 [==============================] - 580s 29ms/step - loss: 0.3185 - accuracy: 0.8845 - val_loss: 0.0510 - val_accuracy: 0.9164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btI-1zW-NoJR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "33c1992a-15e4-4a62-f0fd-d4ee89438c75"
      },
      "source": [
        "# evaluate the performance the new model and report the results\n",
        "score = model.evaluate_generator(validate_generator, 5002/1)\n",
        "print(\"Test Accuracy:\", score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.9212315082550049\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuM-XHvwJi-J",
        "colab_type": "text"
      },
      "source": [
        "  **Accuracy measured is 92.12% which is a lot better than old cnn model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V22ZmO4VyK7d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        },
        "outputId": "0fd00d0d-2e9a-40ab-a95b-5486581b256b"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_50 (InputLayer)        (None, None, None, 3)     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_26  (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 15,242,050\n",
            "Trainable params: 527,362\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6qLNODcRIhc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save transfer learning model for offline prediction purposes\n",
        "model.save('dogsandcat_vgg16_model_tl.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHBk0OK80CNr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "b1160acc-cd4f-4508-dbd2-1d2ac06e13d5"
      },
      "source": [
        "#visualising training results\n",
        "acc_train = transfer_learning_history.history['accuracy']\n",
        "acc_test = transfer_learning_history.history['val_accuracy']\n",
        "\n",
        "loss_train=transfer_learning_history.history['loss']\n",
        "loss_test=transfer_learning_history.history['val_loss']\n",
        "\n",
        "epochs_range = range(2)\n",
        "\n",
        "plt.figure(figsize=(4,4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc_train, label='Training Accuracy')\n",
        "plt.plot(epochs_range, acc_test, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss_train, label='Training Loss')\n",
        "plt.plot(epochs_range, loss_test, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAEICAYAAADGG5iAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydeVyVZdrHvxccDrsKglqAC6KouAtqtmmbZqYtVjpZmqXVazm2TDVNmWPT5DS+s/RaTmZWOiaZjUulllqmk+aaVuKCCgq4gQs7HM459/vH84BHBBSFA3Lu7+fDh+fc9/08z/Us53eue7tuUUqh0Wg0noRXXRug0Wg07kYLn0aj8Ti08Gk0Go9DC59Go/E4tPBpNBqPQwufRqPxONwmfCKyQkRG13TZukREUkXkllo47loReczcflBEvrmYspdwnpYikici3pdqa02h349qHdfj3o+apkrhMy+69M8pIoUunx+szomUUrcrpT6u6bL1ERF5SUTWVZAeJiI2Eel8scdSSs1XSt1WQ3ad80VUSh1WSgUppRyXeLwq3w8xOCgiSRc6ln4/Gt77cYFzKRGJqenjXixVCp950UFKqSDgMHCnS9r80nIiYqltQ68w/g30E5E25dJHAL8opX6tA5tqnIt4P24AmgHRIpLgTtvq+TvpEe9HfeaSqroi0l9E0kXkRRE5BnwoIiEi8qWIZIrIaXM70mUfV/d8jIj8V0Smm2VTROT2SyzbRkTWiUiuiKwWkXdE5N+V2H0xNr4uIj+Yx/tGRMJc8h8SkUMiclJE/lDZ/VFKpQPfAg+Vy3oYmHshO8rZPEZE/uvy+VYR2SMi2SIyAxCXvLYi8q1pX5aIzBeRJmbePKAl8IXpkb0gIq3NX16LWeZqEVkmIqdEZL+IjHM59hQRWSgic817s0tE4iuxub+IpAPTAW/gBDC+3DWvNZ/bKRE5bnqGj4mIt4gsMr1Hm4jYReSwiIwutbX0/TD/zzHfjxVm2WwRyQGmmPdjg4iUiOGRHhWR90vfDxGJEpH/mDadNPO+Mstmlz4XEWkmIgXme6Hfj8t8P6pCRBqbx8g07+UrIuJl5sWIyPfmtWWJyKdmuojI30XkhIjkiMgvcgGv+XLa+FoAoUArYLx5rA/Nzy2BQmBGFfv3AfYCYcBbwAciIpdQ9hNgM9AUmML5L5MrF2Pjb4BHMDwVK/A8gIh0Amaax7/aPF+FL6PJx662iEgs0N20t7r3qvQYYcB/gFcw7sUB4FrXIsCbpn0dgSiMe4JS6iHO9crequAUiUC6uf9w4M8icpNL/lCzTBNg2QVsbgF0BR4AXgTuAeaZ19wJ45mGmOeKAU6b+z1r5lmACUAC8DbGc6+MPsAxc3slkAe8Yd6PJqadkcBxDHFBjHarL4FDQGsgAlgMzAFmm/9Ln8tIYA1Qgn4/aur9qIz/AxoD0cCNGM/rETPvdeAbjPcm0iwLcBtG7aK9ue/9wMkqz6KUuqg/IBW4xdzuD9gAvyrKdwdOu3xeCzxmbo8B9rvkBQAKaFGdshgvhR0IcMn/N/Dvi7ymimx8xeXz/wArze3JQKJLXqB5D26p5NgBQA7Qz/z8BrD0Eu/Vf83th4EfXcoJxov4WCXHvQv4qaJnaH5ubd5LC8aXwAEEu+S/CXxkbk8BVrvkdQIKq3g/7ECmeWw/IBu428wfCeyp6JoxfuD+WckzL7W1tOxaDIHab96nw1W9H+b9OGW+I9eU2lfBfetjHqs7hiBvxfgy6ffjEt+PCs6tgJhyad7mPevkkvY4sNbcngvMAiLL7XcTsA/oC3hdzHf/cjy+TKVUUekHEQkQkfdM9zQHWAc0kcp7hEp/oVFKFZibQdUsezVwyiUNIK0ygy/SxmMu2wUuNl3temylVD5V/KqYNn0GPGx6pw9iPLhLuVellLdBuX4WkeYikigiGeZx/43xy38xlN7LXJe0QxieUCnl742fVN6WZgcWKqXs5nuyBPibiBzC8GbaUvE1R2FUjSt65pVRWjat3PsRZ9qR7HI/Su2NAg4ppeylByl9LsBC87p/wPBeYjA8mIrugX4/zlKd96MiwgAf87gVneMFDDHfbFalxwIopb7F8C7fAU6IyCwRaVTViS5H+MqHdXkOiAX6KKUaYbie4NLGUAscBUJFJMAlLaqK8pdj41HXY5vnbHqBfT7G8BRuBYKBLy7TjvI2COde758xnksX87ijyh2zqlA8RzDuZbBLWksg4wI2VUQ44AuMEpFjYrQDP4BRdbsdo+qyv/Qyyu2bhlGNrAzXZ92iXF756xuNUR3t7XI/SsUjDWhZ7otZ9lwwqoulw0Q+d/2RrwT9flw+WRjNCa0qOodS6phSapxS6moMT/BdMXuGlVJvK6V6YXia7YHfVXWimhzHF4zRFnFGREKB12rw2BWilDqEUQ2ZIiJWEbkGuLOWbFwEDBGR60TECkzlwvdvPXAGwz1PVErZLtOOr4A4EbnH/MJO5NwvfzBG+1a2iERw/sM/jtF2ch5KqTRgA/CmiPiJSFfgUQyvoLrciuFplbZbdQc+AIqAgRieVGmPptX8MpV+oWZjtAf6mY3WXUWkVECOYXxZwWi7ansBO7wwqrOTRKQ1xjPzN/M2YwjFNBEJFBE/oAPmc8EQoTvMshdzD/T7UX2s5rH8zPsPhrf9hogEi0grjDbf0s6o++RsJ89pDKF2ikiCiPQRER8gH+M9c1Z14poUvn9gvFRZwI8Yjczu4EGM9pqTwJ+AT4HiSspeso1KqV0Yje2fYHxhTmO0n1S1j8KovrQy/1+WHUqpLOA+YBrG9bbDEJFS/gj0xGhP+wqjoduVN4FXROSMiDxfwSlGYrTrHMFo6H9NKbX6YmwrxyAgz/yFPqaUOobRhnUUo6d3NfAXs2wGkIzRYA3wNwxR6ozRBvYBZ8XqDxhf1uswql4bLmDHHzGqzc9iNPT7Y1TBipUxNu1OjGrsYYxnWcTZ5/Ifcx8wBKpK9PtxSezCEPjSv0eApzHE6yDwX4z7OccsnwBsEpE8jKaH3yqlDgKNgPcx7vkhjGv/a1UnFrNxsMFgdnHvUUrVusepufKozvshInOAI0qpV2rfMo07ueLn6ppublsR8RKRQcAwjIZ0jeaS3w+zanwPhsepaWDU59HtF0sLDJe9KUbV4kml1E91a5KmHlHt90NEXgeeAd5USqXUvokad9PgqroajUZzIa74qq5Go9FUl4ZQ1a2UsLAw1bp167o2Q+PCtm3bspRS4TV5TP2c6x+18ZxrkgYtfK1bt2br1q11bYbGBXPmRo2in3P9ozaec02iq7oajcbj0MKn0Wg8Di18Go3G42jQbXyaK4dt27Y1s1gsszGmqlXrB/mtt95i9+7dtWOYpkr8/PyIjIzEx8enrk2pFlr4NPUCi8Uyu0WLFh3Dw8NPe3l5VWtwaVJSUquOHTvWlmmaSlBKcfLkSdLT02nTpnwU/fqNrupq6gudw8PDc6orepq6Q0Ro2rQpRUUXithV/9DCp6kveGnRu/KQSleLqN9o4dPUPErBsV/h2zcgc59bT51TWEJmbjFFJQ70dExNZWjh09QMSkHGdlg9Bf6vJ/zrWlg/HdI2udWMnKISjmYXsu94LnuO5ZJ+qoAzBTbsjirjUnLy5Em6d+9O9+7dadGiBREREWWfbTZblftu3bqViRMnXtC2fv36VetaKmPt2rUMGTKkRo7lqejODc2l43RC+hbYvQySlkH2YRBviL4R+k2EDkMgyL2zliJDAmgW7EtusZ28IjvZRSWcKjCEK8BqIcjXQrCfBX+rN14u1bSmTZuyY8cOAKZMmUJQUBDPP382FqfdbsdiqfjrEh8fT3z8hVdS3LDhQnFTNe5Ce3ya6uF0QOp/Yfnv4O+dYM5tsHkWNOsIw96F3+2HhxZD/CNuF71SrBZvmgb60qppIJ2uakTb8CCaNzIim2fmFnEgM4/dR3JIzcrnZF4xxXZHhccZM2YMTzzxBH369OGFF15g8+bNXHPNNfTo0YN+/fqxd+9e4FwPbMqUKYwdO5b+/fsTHR3N22+/XXa8oKCgsvL9+/dn+PDhdOjQgQcffLCsWr58+XI6dOhAr169mDhxYrU8uwULFtClSxc6d+7Miy++CIDD4WDMmDF07tyZLl268Pe//x2At99+m06dOtG1a1dGjBhRndvbINAen+bCOEoMsUtaCnu+hPxMsPhBzC3QaRi0Hwh+jWvsdL9btDNq37HcgAuXNHCWFBOwPrvKMp2ubsRrd8ZhdzrJL7aTW2R4hDlFJQBYLV4E+/oQ5GfB6dI2mJ6ezoYNG/D29iYnJ4f169djsVhYvXo1L7/8Mp9//vl559qzZw/fffcdubm5xMbG8uSTT543zu2nn35i165dXH311Vx77bX88MMPxMfH8/jjj7Nu3TratGnDyJEjL/YWcOTIEV588UW2bdtGSEgIt912G0uWLCEqKoqMjAx+/fVXAM6cOQPAtGnTSElJwdfXtyzNk9DCp6kYuw0OroXdS2HPV1B4GnwCof1thtjF3Aq+la0GWn+xeHnR2N9KY38rSilsdmdZtfh0gY2T+cVk5hZTIlaKShwMvfsevLyMilF2djajR48mOTkZEaGkpKTCc9xxxx34+vri6+tLs2bNOH78OJGR564t3rt377K07t27k5qaSlBQENHR0WVj4kaOHMmsWbMu6rq2bNlC//79CQ83vOwHH3yQdevW8eqrr3Lw4EGefvpp7rjjDm677TYAunbtyoMPPshdd93FXXfdVf0beYWjhU9zlpJCOPCt4dntXQnF2eDbCGJvh45DIeZm8PG/4GFWrlzJb3/7WxwOB4899hgvvfTSOfki8gTGwjwOjFW/xu/YsYOioiLrrl27Oo/u4FtEhyYEBATkRUdHH77Q+ZKSknp16tSp2pcrIvj6eOPr401YkC9OpSgodhBg9UYpKLQ5yLV7s/toDkG+Prz4+z9www39Wbx4MampqfTv37/C4/r6+pZte3t7Y7fbL6lMTRASEsLOnTv5+uuv+de//sXChQuZM2cOX331FevWreOLL77gjTfe4Jdffqm0DbMh4jlXqqkYWz4kf2N0Tuz7GkrywT8EOt5peHbRN4LF98LHMXE4HEyYMIFVq1YRGRlJQkICQ4cOpZwwfaKU+heAiAzFWFkNAKvVWty5c+ekmrq86uAlQpCfhWA/H4KCfGkc4ENYkC/Bfj7kFts5nnUKFRjCvuO5vPev91EKnM6aGzITGxvLwYMHSU1NpXXr1nz66acXvW/v3r2ZOHEiWVlZhISEsGDBAp5++mmysrKwWq3ce++9xMbGMmrUKJxOJ2lpaQwYMIDrrruOxMRE8vLyaNKkSY1dS31HC58nUpRjiFzSEti/BuyFEBAGXe+HTkOh9fXgfWlzLzdv3kxMTAzR0cbyrCNGjGDp0qXnCJ9SKsdll0CqXsi6zvASIdDXQlRoAEopJr/8Eo+OfYQP/u9/ufam27A7new6msORM4XY7E4KL3PsoL+/P++++y6DBg0iMDCQhISESsuuWbPmnOrzZ599xrRp0xgwYABKKe644w6GDRvGzp07eeSRR3A6jeE8b775Jg6Hg1GjRpGdnY1SiokTJ3qU6EEDX3MjPj5e6QCVJgWnYO8KY+jJgW/BYYOgFobQdRoGLa8BL+/LPs2iRYtYuXIls2fPBmDevHls2rSJGTNmACAi25RS8SIyAWO9Wytw044dO1bFxsbm7Nq1K87X17fYy8vLERERkdG4ceO8is5z7NixsKysrHAAp9MZ0LVr18u2vTo4nYp829lOkiKzZ9jH26tsyEyQrwWLd/UGTuTl5REUFIRSigkTJtCuXTueeeaZ2riEGmP37t2Unytd+pzryKQLoj2+hkx+ltELm7QUUtaB0w6NoyBhnCF2kQngVTcjmpRS7wDviMhvgFcArFZrSdeuXX/28fFx5ObmBhw4cCCmc+fOv1oslvNGH7do0SKrRYsWWWC08bnXevDyEoL9fAj2Mzxjm91JXrGdvKIScopKOG2OHfT38TZE0M+HgHJjByvi/fff5+OPP8Zms9GjRw8ef/zxWr8WT0QLX0Mj5+hZsTv0AygnhLSBa54yvLure0Itzq+MiIggLS2t7HN6ejoRERFV7ZIIzAROe3l5KS8vLwdAcHBwga+vb3FhYaFfcHBwQa0ZXENYLV6EWqyEBhq9xYUljjJvMDPXxoncYqMN0dditCP6WrBavM6b6/rMM8/Uew+vIaCFryFwJg12f2GIXdomQEFYLFz/nOHZNe9cq2LnSkJCAsnJyaSkpBAREUFiYiKffPLJOWVEpJ1SKtn8eAeQDITZbDaLj4+PXUQoLCy0FhcX+/r5+RW7xfAaREQIsFoIsFpo3ggcTid5xQ7yikrILbaTc8YcO+jtZXamGNVi7zryvj0RLXxXKqcOGj2xu5dBxjYjrXkXGPCyMfSkWYc6MctisTBjxgwGDhyIw+Fg7NixxMXFMXnyZNdpXU+JyC1ACXAaGA18lZOTE3T06NEIEVGAioqKOuTj41PxtIorCG8vLxr7e9HY36gWF9sd5BUZ7YPZBSWcyrchCP5W7zIRDLB6X7GRT64EdOfGlUTmPmNAcdJSOPaLkXZ1D0PoOg2Dpm3r1r6LoLJG7507d6Z269Yt61KOeanj+OoDTqWM8YJFdvKKSyiwGTrv7SUunSQ+WC311xvUnRuamkUpOJFkCF3SMsg0w6tH9obb3jDG2oW0qlsbNZdF6ZCZQF8L4IfdYXSSGEJoJ7uwBCjE13LWGwz0teDtpb3By6H+/ox4KkrBkZ9g9R/h/3rBzH7w/VsQ0BRufwue3Q2PrYJ+T2nRq0EGDBjA119/fU7aP/7xD5588slK9+nfv3/Zer6DBw+ucM7rlClTmD59epXnXrJkCUlJxphti7cXf5v2J/Zu30CHFsG0bx7MVY39sVq8OJVvI/VkPklHcziYmceJ3CIKbfZKxw7q8FWVoz2++oDTabTTJS0x2uzOmOGd2lxvCFyHIRDUrK6tbNCMHDmSxMREBg4cWJaWmJjIW2+9dVH7L1++/JLPvWTJEoYMGVI2yHvq1KlleX4+3vj5eBMe7Fs2drDUIzyWXcQxjPnHxpAZwyP0qebYQU9E36G6wumA1B9gxYvw9zj44BbY9B6Ed4ChM4zwTg8vhfixWvTcwPDhw/nqq6/Kgo6mpqZy5MgRrr/+ep588kni4+OJi4vjtddeq3D/1q1bk5VlNFG+8cYbtG/fnuuuu64sdBUYY/QSEhLo1q0b9957LwUFBWzYsIFly5bxu9/9ju7du3PgwAHGjBnDokWLAGOGRo8ePejSpQuPPfYoVnFyVWN/buvThYXv/Y2HhgzgnluuYeevSaSdKmD30RySj+dyNLvQ8AYrsFWHr9Ien3tx2OGQGd5p95eQfwK8fc3wTlOM8E7+njV1qEKWTIjiRNJFh6VqVaJgU2DVhVp0gdunVZodGhpK7969WbFiBcOGDSMxMZH7778fEeGNN94gNDQUh8PBzTffzM8//0xlM0W2bdtGYmIiO3bswG6307NnT3r1MsZX33PPPYwbNw6AV155hQ8++ICnn36aoUOHMmTIEIYPH37OsYqKihgzZgxr1qyhffv2PPzww8ycOZNJkyYB0LxZODt3/MS7777L4o9nMmPme+QW2ckttpOVZ+NIdhF5RXZSsvIJNscPnjxxTIevws0en4gMEpG9IrJfRF6qIL+ViKwRkZ9FZK2IRLrkrRSRMyLypTttvmzsNkheBUufguntYO4w2JkIrfrB8DnwwgEY+Ql0e0CLXh1TWt0Fo5pbGg9v4cKF9OzZkx49erBr166y9riKWL9+PXfffTcBAQE0atSIoUOHluX9+uuvXH/99XTp0oX58+eza9euKu3Zu3cvbdq0oX379gCMHj2adevWleXfc889APTq1YtDhw7hb7XQrJEfbcOD6HRVI1o08sPHW7DZnRwxw/Ev+WYdvftdh09gYxCvsvBV0dHRZeGrVq5cSaNGjYCz4av+/e9/N6joLW67EhHxBt4BbgXSgS0iskwp5foWTQfmKqU+FpGbgDeBh8y8vwIBQP2fw1NS5BLeaYUR3skaDLGDjGEnbW8G60U7NJ7HXe+kXbjQWQ7V0HCWYcOG8cwzz7B9+3YKCgro1asXKSkpTJ8+nS1bthASEsKYMWMueTnFMWPGsGTJErp168ZHH33E2rVrL8ve0tBWFYW18vYyeov9fLyJbRGMzW4MmbFavLDZnRw+VYAAJ3KKyLfZsQYEs2PHDr755huPCF/lTo+vN7BfKXVQKWXDmKo0rFyZTsC35vZ3rvlKqTVArjsMvSRs+bBrCSwaC39tC4kjYd9K6DgERn5qeHb3zjaGoGjRq5cEBQUxYMAAxo4dW+bt5eTkEBgYSOPGjTl+/DgrVqyo8hg33HADS5YsobCwkNzcXL744ouyvNzcXK666ipKSkqYP39+WXpwcDC5uee/2rGxsaSmprJ//37ACPhw4403XtK1WS3eNA3yZcgtN7Bzy0YaSxFNA334cvEi4nr0ZeveQyRlnCG+/yCef3ky27ZtPyd81V/+8heys7PJy6swZsQVhzulOwJw/SVPB/qUK7MTuAf4J3A3ECwiTZVSJy/2JCIyHhgP0LJly8sy+IIU5Zix7JZA8uqz4Z0632t4dm1uuOTwTpq6YeTIkdx9991lVd5u3brRo0cPOnToQFRUFNdee22V+/fs2ZMHHniAbt260axZs3NCS73++uv06dOH8PBw+vTpUyZ2I0aMYNy4cbz99ttlnRoAfn5+fPjhh9x3333Y7XYSEhJ44oknqnU9lYWvGjLo1rLwVf8zZgQ/btnOYw89RondCSgmvjSZpIwzjB3xG/LzchBoUOGr3DZzQ0SGA4OUUo+Znx8C+iilnnIpczUwA2gDrAPuBTorpc6Y+f2B55VSFzU4qVZmbhSeNqITJy2FA2vM8E7NzdkTQ6FlP/C+8qsCtYWeuVG/UUpRbD87iDq/2I5TKXP+sXdZJ4m/z9kpdXrmRtVkAFEunyPNtDKUUkcwPD5EJAi4t1T06pT8k0bEk93LjHUonHZoFAkJj5nhnXrXWXgnjaYmEZGysYNnw/Hby9YlOZZTBDnG2MHSSDOOGoxC7S7cKXxbgHYi0gZD8EYAv3EtICJhwCmllBP4PTDHjfadS+5x2GNGPEn9AZQDQlrDNROg4zCIqN3wThpNfcAIx+9DkJ8PNIYSR2ncQcMjPFNo43h2EdbjubRvHlzX5l40bhM+pZRdRJ4Cvga8gTlKqV0iMhXYqpRaBvQH3jSjc6zDWJAGABFZD3QAgkQkHXhUKfV1+fNcFtnpZninZXB4I6CgaTu47hnDs2vRRYtd7eF0Op3i5eV15bkPHoSPtxchAVZCAsy4gzYHRZk+xIRfWSvuubUxSim1HFheLm2yy/YiYFH5/cy862vFqNOphtAlLYUMsz2wWRz0/73RZhfeQYude/g1MzOzU3h4eLYWvyuHgtwzhDcJwusKC5rgma3wWfvPzos9utNIu6o73DzZqMaGxdStfR6I3W5/7NixY7OPHTvWmWoOszp58qSOXVdH+Pn5nbdm8JWA5wjf6VRjxkTSUiPUExhrTtz6uuHZhbSuS+s8nl69ep0Ahl6wYAU0uLiLmlrHc4QvYzusnWZMFRv0F2MgceMq14LQaDQNFM8Rvtjb4bm9ENy8ri3RaDR1jOcIn4+/8afRaDwePepWU+OsXLmS2NhYYmJimDbt/FBQIvKEiPwiIjtE5L8i0skl7/dm9J69IjLwvJ01mhpAC5+mRnE4HEyYMIEVK1aQlJTEggULKgrj9IlSqotSqjvwFvA3AFMARwBxwCDgXTOqj0ZTo2jh09QomzdvJiYmhujoaKxWKyNGjGDp0qXnlFFK5bh8DISyQMHDgESlVLFSKgXYjxHVR6OpUbTwaWqUjIwMoqLOTsmOjIwkIyPjvHIiMkFEDmB4fBPN5Ioi+FTY9S4i40Vkq4hszczMrCnzNR6CFj5NnaCUekcp1RZ4EXjlEvafpZSKV0rFh4eH17yBmgaNFj5NjRIREUFa2lmnLT09nYiIKsdLJgJ3mdsXjOCj0dQEWvg0NUpCQgLJycmkpKRgs9lITEw8Z90JABFp5/LxDiDZ3F4GjBARXzOKTztgs1sM13gUnjOOT+MWLBYLM2bMYODAgTgcDsaOHUtcXByTJ08mPr4sLuVTInILUAKcBkYDmNF6FgJJgB2YoJRy1MV1aBo2bovAXBfoOZz1j9qIzKufc/2jvkdg1lVdjUbjcWjh02g0HocWPo1G43Fo4dNoNB6HFj6NRuNxaOHTaDQehxY+jUbjcWjh02g0HocWPo1G43Fo4dNoNB6HW4VPRAaZIcX3i8hLFeS3EpE1IvKziKwVkUiXvNEikmz+jXan3RqNpmHhNuEzQ4i/A9wOdAJGuq61YDIdmKuU6gpMBd409w0FXgP6YETkfU1EQtxlu0ajaVi40+PrDexXSh1UStkw4rANK1emE/Ctuf2dS/5AYJVS6pRS6jSwCmNNBo1Go6k27hS+iwkrvhO4x9y+GwgWkaYXuS+gQ5JrNJoLU986N54HbhSRn4AbMaLvVisemw5JrtFoLoQ7A5FeMKy4UuoIpscnIkHAvUqpMyKSAfQvt+/a2jRWo9E0XNzp8W0B2olIGxGxYqyfusy1gIiEiUipTb8H5pjbXwO3iUiI2alxm5mm0Wg01cZtwqeUsgNPYQjWbmChGWp8qoiULsrQH9grIvuA5sAb5r6ngNcxxHMLMNVM02g0mmrj1jY+pdRypVR7pVRbpVSpqE1WSi0ztxcppdqZZR5TShW77DtHKRVj/n3oTrs11WPlypXExsYSExPDtGnTzssXkWdFJMkcr7lGRFq55DlEZIf5t+y8nTWaGqC+dW5ornAcDgcTJkxgxYoVJCUlsWDBApKSksoX+wmIN8drLsJYVLyUQqVUd/NvaPkdNZqaQAufpkbZvHkzMTExREdHY7VaGTFiBEuXLj2njFLqO6VUgfnxR4zOKo3GbWjh09QoGRkZREWd7byPjIwkI6PKNcEfBVa4fPYzx2H+KCJ3VbaTHq+puRz0urqaOkNERgHxGGM2S0sESNAAACAASURBVGmllMoQkWjgWxH5RSl1oPy+SqlZwCwwlpd0i8GaBoP2+DQ1SkREBGlpZyfZpKenExFx/iQbc0HxPwBDy3ViZZj/D2KM1exRyyZrPBAtfJoaJSEhgeTkZFJSUrDZbCQmJjJ06Ll9FCLSA3gPQ/ROuKSHiIivuR0GXAuc1zOi0VwuuqqrqVEsFgszZsxg4MCBOBwOxo4dS1xcHJMnTyY+Pr602F+BIOAzEQE4bPbgdgTeExEnxo/yNKWUFj5NjSNKNdzmkfj4eLV169a6NkPjgohsU0rFX7jkxaOfc/2jNp5zTaKruhqNxuPQwqfRaDwOLXwajcbj0MKn0Wg8Di18Go3G49DCp9FoPA4tfBqNxuPQwqfRaDwOLXwajcbj0MKn0Wg8Di18Go3G49DCp9FoPA4tfBqNxuPQwqfRaDwOLXwajcbj0MKn0Wg8DrcKn4gMEpG9IrJfRF6qIL+liHwnIj+Zi00PNtOtIvKhiPwiIjtFpL877dZoNA0LtwmfiHgD7wC3A52AkSLSqVyxV4CFSqkewAjgXTN9HIBSqgtwK/C/IqK9VY1Gc0m4Uzx6A/uVUgeVUjYgERhWrowCGpnbjYEj5nYn4FsAc3GaMxjLEmrqIStXriQ2NpaYmBimTZt2Xr6IPCsiSaZXv0ZEWrnkjRaRZPNvtFsN13gM7hS+CCDN5XO6mebKFGCUiKQDy4GnzfSdwFARsYhIG6AXEIWm3uFwOJgwYQIrVqwgKSmJBQsWkJR03npBPwHxSqmuwCLgLQARCQVeA/pg/FC+JiIhbjRf4yHUt+riSOAjpVQkMBiYZ1Zp52AI5VbgH8AGwFHRAURkvIhsFZGtmZmZbjJbU8rmzZuJiYkhOjoaq9XKiBEjWLp06TlllFLfKaUKzI8/ApHm9kBglVLqlFLqNLAKGOQ24zUegzuFL4NzvbRIM82VR4GFAEqpjYAfEKaUsiulnlFKdVdKDQOaAPsqOolSapZSKl4pFR8eHl7jF6GpmoyMDKKizj7myMhIMjLKP+ZzeBRYYW5fTK0A0D9wmsvDncK3BWgnIm1ExIrRebGsXJnDwM0AItIRQ/gyRSRARALN9FsBu15v9cpHREZhtNX+tbr76h84zeXgtgXFlVJ2EXkK+BrwBuYopXaJyFRgq1JqGfAc8L6IPIPR0TFGKaVEpBnwtbnQdAbwkLvs1lSPiIgI0tLOOm3p6elERJzvtInILcAfgBuVUsVmcgbQ36VYJLC2tmzVeC5uEz4ApdRyjE4L17TJLttJwLUV7JcKxNa2fZrLJyEhgeTkZFJSUoiIiCAxMZFPPvnknDIi0gN4Dxhk9tKX8jXwZ5cOjduA37vFcI1H4Vbh0zR8LBYLM2bMYODAgTgcDsaOHUtcXByTJ08mPr5sBNJfgSDgMxEBOKyUGqqUOiUir2M0iwBMVUqdcv9VaBo6opSqaxtqjfj4eLV169a6NkPjgohsU0rV6BhM/ZzrH7XxnGuS+jacRaPRaGodLXwajcbj0MKn0Wg8Di18Go3G49DCp9FoPA4tfBqNxuPQwqfRaDwOLXwajcbj0MKn0Wg8Di18Go3G49DCp6kVcotKGDd3K/uO59a1KRrNeWjh09Q42YUlPPTBZr7bc4JDJwsuvING42Z0dBZNjZJdUMJDczax+2gO7z7Yk1s7Na9rkzSa89DCp6kxTufbGPXBJpKP5/GvUb24uaMWPU39RAufpkY4lW/jwdmbOJCZx3sP92JAbLO6NkmjqRQtfJrLJiuvmFGzN5GSlc/sh+O5ob1eA0NTv9HCp7ksMnOL+c37P5J2uoA5YxK4Niasrk3SaC6IFj7NJXMip4iR7//IkTNFfDimN9e0bVrXJmk0F4UWPs0lcSy7iN+8/yPHcor4eGxvercJrWuTNJqLRo/j01SbI2cKeWDWRk7kFjO3AtFbuXIlsbGxxMTEMG3atPP2F5EbRGS7iNhFZHi5PIeI7DD/yq+7rNHUCNrj01SL9NMFjHz/R87klzD30d70bBlyTr7D4WDChAmsWrWKyMhIEhISGDp0KJ06dXItdhgYAzxfwSkKlVLda+0CNBq0x6epBmmnCnjgvR/JLijh34/1OU/0ADZv3kxMTAzR0dFYrVZGjBjB0qVLzymjlEpVSv0MON1kukZzDlr4NBfFoZP5PPDeRvKK7cx/rC/doppUWC4jI4OoqKiyz5GRkWRkZFTnVH4islVEfhSRuyorJCLjzXJbMzMzq3N8jca9wicig0Rkr4jsF5GXKshvKSLfichPIvKziAw2031E5GMR+UVEdovI791pt6eTkpXPA+/9SGGJg0/G9aFLZOPaPF0rcz3W3wD/EJG2FRVSSs1SSsUrpeLDw/W4QU31cJvwiYg38A5wO9AJGCkincoVewVYqJTqAYwA3jXT7wN8lVJdgF7A4yLS2h12ezoHMvN44L2N2BxOPhnXl7irqxa9iIgI0tLSyj6np6cTERFx0edTSmWY/w8Ca4Eel2K3RlMV7vT4egP7lVIHlVI2IBEYVq6MAhqZ242BIy7pgSJiAfwBG5BT+yZ7NsnHc3ngvR9xKsWCcX3peFWjC+6TkJBAcnIyKSkp2Gw2EhMTGTp06EWdT0RCRMTX3A4DrgWSLucaNJqKcGevbgSQ5vI5HehTrswU4BsReRoIBG4x0xdhiORRIAB4Ril1qqKTiMh4YDxAy5Yta8p2j2PvsVwenP0jIsKCcX2JaRZ8UftZLBZmzJjBwIEDcTgcjB07lri4OCZPnkx8fDwAIpIALAZCgDtF5I9KqTigI/CeiDgxfpSnKaW08GlqnPo2nGUk8JFS6n9F5Bpgnoh0xvAWHcDVGF+W9SKy2qwOnYNSahYwCyA+Pl65z/SGw+6jOTw4exMWL2HB+L60DQ+q1v6DBw9m8ODB56RNnTq1bFsptQWILL+fUmoD0OWSjNZoqoE7q7oZQJTL50gzzZVHgYUASqmNgB8QhtHQvVIpVaKUOgH8AMTXusUeyK8Z2Yx8/0es3l58+vg11RY9jeZKwJ3CtwVoJyJtRMSK0XlRfmT+YeBmABHpiCF8mWb6TWZ6INAX2OMmuz2GX9KzeXD2JgJ8vPn08b60CQusa5M0mlrBbcKnlLIDTwFfA7sxem93ichUESlt/X4OGCciO4EFwBillMLoDQ4SkV0YAvqhOQBWU0PsSDvDb2b/SJCvhU8fv4ZWTbXoaRoubm3jU0otB5aXS5vssp2E0ZNXfr88jCEtmlpg++HTjP5gM00CfVgwri+RIQF1bZJGU6vUt84NjZvZmnqKMR9uoWmQlQXj+nJ1E/+6NkmjqXX0lDUPZtPBkzw8ZzPhwb58Ov4aLXoaj0ELn4ey8cBJxny4hasa+/Hp+L60aOxX1yZpNG5DC58H8sP+LB75aDORIf4sGN+XZo206Gk8C93G52Gs25fJuLlbad00kPnj+hAW5FvXJmk0bkcLnwfx3d4TPD5vG23Dg5j/WB9CA611bZJGUyfoqq6HsGb3cR6fu412zYL4RIuexsPRHp8H8M2uY0z4ZDsdr2rEvLF9aBzgU9cmaTR1ivb4Gjgrfz3K/8zfTtzVjZn3qBY9jQa0x9eg+erno0xM/InuUU346JEEgv206Gk0oIWvwbJ0RwbPLtxJz5ZN+PCR3gT56ket0ZSiq7oNkMU/pfPMpzuIbxXCR1r0NJrz0MLXwFi0LZ1nF+6kb3RTPnwkgUAtehrNeehvRQPi0y2Heek/v3BdTBizHorH3+pd1yZpNPUS7fE1ED7ZdJgXP/+FG9qF8/7DdSt6K1euJDY2lpiYGKZNm3ZevojcICLbRcQuIsPL5Y0WkWTzb7TbjNZ4FFr4GgDzNqby8uJfuKlDM957qBd+PnUneg6HgwkTJrBixQqSkpJYsGABSUnnrRd0GBgDfOKaKCKhwGsYi1D1Bl4TkRA3mK3xMLTwXeF8+EMKry7dxS0dmzNzVM86FT2AzZs3ExMTQ3R0NFarlREjRrB06dJzyiilUs0I2s5yuw8EVimlTimlTgOrgEHusVzjSWjhu4KZvf4gf/wiiYFxzXn3wZ74Wuq+TS8jI4OoqLNrSkVGRpKRUX5NqUqpaAnSClcjF5HxIrJVRLZmZmZeqrkaD0UL3xXKe98f4E9f7WZwlxbM+E1PrBbPepRKqVlKqXilVHx4eHhdm6O5wvCsb0sD4Z3v9vPmij3c2e1q3h7RAx/v+vMYIyIiSEs767Slp6cTEVGh01YRF7MEqUZz2dSfb4zmonh7TTJ//Xovd3W/mr/f3w1LPRI9gISEBJKTk0lJScFms5GYmMjQoUMvvKPB18BtIhJidmrcZqZpNDWKHsd3haCU4u+rk3l7TTL39Izgr8O74e0ldW3WeVgsFmbMmMHAgQNxOByMHTuWuLg4Jk+eTHy8sQa8iCQAi4EQ4E4R+aNSKk4pdUpEXsdYQhRgqlLqVN1ciaYhI8aytQ2T+Ph4tXXr1ro247JRSvG/3+xjxnf7uT8+kjfv6VovRe9iEJFtSqn4mjxmQ3nODYnaeM41ifb46jlKKf6yci//+v4AI3tH8cZdXfC6QkVPo6kvuLWBSEQGicheEdkvIi9VkN9SRL4TkZ9E5GcRGWymPygiO1z+nCLS3Z221wVKKf68fDf/+v4Ao/q21KKn0dQQbhM+EfEG3gFuBzoBI0WkU7lirwALlVI9gBHAuwBKqflKqe5Kqe7AQ0CKUmqHu2yvC5RSTP0yiffXpzCmX2teH9ZZi55GU0O40+PrDexXSh1UStmARGBYuTIKaGRuNwaOVHCckea+DRalFK8t28WHP6Qy9to2vHZnJ0S06Gk0NYU72/gqGpXfp1yZKcA3IvI0EAjcUsFxHuB8wWwwOJ2KV5f+yvxNhxl/QzS/v72DFj2NpoapX4PADG/uI6VUJDAYmCciZTaKSB+gQCn1a2UHuJKnMjmdipcX/8L8TYd5sn9bLXoaTS3hTuG7mFH5jwILAZRSGwE/IMwlfwSwoKqTXKlTmRxOxQuf/0ziljSevimGFwbGatHTaGoJdwrfFqCdiLQRESuGiC0rV+YwcDOAiHTEEL5M87MXcD8NsH3P4VT87rOdLNqWzqRb2vHcbVr0NJraxG1tfEopu4g8hTEFyRuYo5TaJSJTga1KqWXAc8D7IvIMRkfHGHV2hPUNQJpS6qC7bHYHdoeT5z7bydIdR3ju1vY8fXO7ujZJo2nwuHUAs1JqObC8XNpkl+0k4NpK9l0L9K1N+9xNicPJpE938NXPR3lhUCz/0z+mrk3SaDwCPXOjjihxOJm44CdW/HqMlwd3YPwNbevaJI3GY9DCVwfY7E6e+mQ73yQd59UhnXj0ujZ1bZJG41Fo4XMzxXYHE+ZvZ/XuE/xxaByj+7Wua5M0Go9DC58bKSpx8OS/t/Hd3kxev6szD/VtVdcmaTQeiRY+N1FU4mD8vG2s25fJm/d0YWTvlnVtkkbjsWjhcwOFNgfj5m7lhwNZvHVvV+5PiLrwThqNptbQwlfLFNjsPPrRVn5MOcn04d24t1dkXZuk0Xg8WvhqkfxiO498tIWtqaf4+/3duavHRS+6o9FoapH6FqSgwZBXbGf0nM1sO3Saf47o4VGit3LlSmJjY4mJiWHatGnn5YuIr4h8agak3SQirc301iJS6BJw9l9uNl3jIdTImhvbtm1rZrFYZgOdqUdievLkyVZXXXWV28/rVIqTeTZsdiehgVb8rXW/0Le7cDgcDB48mHnz5hEfH0+/fv1YsGABnToZMWdFZBswB+iqlHpCREYAdyulHjAF8EulVOfqnFOvuVHHFOWAX6NzkjxizQ2LxTK7RYsWHcPDw097eXnVm9WLkpKSWnXs2NGt57Q7naRmFRDSyEHLpgE09vdx6/nrmo0bN9KxY0fi4uI4ceIEI0aMYOnSpWXCZzIMI/YiwCJghuioDFcOTicc+Qn2r4b9qyBjOzy3F4KunGhINdXG17m+iV5dYHc4ScnKp8jupFXTABp5mOgBZGRkEBUVRdOmTcnMzCQyMpJNmzaVL1YWlNYMXpENNDXz2ojIT0AO8IpSan1F5xGR8cB4gJYt9dCgWic/C/avMYTuwLdQcBIQiOgJNzxf19ZVm5oSPi8tei6iF+qZoufKJTpwR4GWSqmTItILWCIicUqpnPIFlVKzgFlgVHUvy1jN+TgdkLENklcZYndkB6AgIAxibjH+2t4EgWEXPFR9RPfq1gB2h5ODWfkU2520bhpAsJ/nil5ERARpaWdXGEhPTyci4ryOndKgtOkiYsFYX+WkGYKsGEAptU1EDgDtAd2A5w5yj5vV19WGV1d0BsQLIuJhwMuG2F3VHbzqTTP+JdMghO/YsWPe/fv3jwXIysry8fLyUqGhoXaAn3/+GavVWum+W7duZe7cubz99ttVnqNfv35s2LDhvPQS09OzVVP0Jk2axGeffUZaWhpeDeBFKiUhIYHk5GRSUlKw2WwkJibyySeflC+2DBgNbASGA98qpZSIhAOnlFIOEYkG2gENKv5ivcJRAulbznp1x34x0oOaQ4c7IOZmiB4AAaF1a2ct0CCEr0WLFo49e/YkATz77LNXBwUFOaZOnXo8KSmpl9VqxW63Y7FUfKnx8fHEx1+486ky0TuYmU+JwxC9oIsUPafTyeLFi4mKiuL7779nwIABF7VfdanqumsLi8XCjBkzGDhwIEVFRTz++OPExcUxefJk1/v8AcZ6KvuBUxjRuMEINjtVREoAJ/CEUuqUWy+goZOdcdarO7gWinNAvCGqD9w82fDqmndpEF5dVdT4t+J3i3ZG7TuWG1CTx2zfIrjgr8O7pV245Fnuvffe1haLhdTUVK699lpGjBjBb3/7W4qKivD39+fDDz8kNjaWtWvXMn36dL788kumTJnC4cOHOXjwIIcPH2bSpElMnDgRgKCgIPLy8li7di1TpkwhtGlTduz8hY5dupO4YD5Bfj4sX76cZ599lsDAQK699loOHjzIl19+eZ5ta9euJS4ujgceeIAFCxaUCd/x48d54oknOHjQcHJmzpxJv379mDt3LtOnT0dE6Nq1K/PmzWPMmDEMGTKE4cOHn2ffq6++SkhICHv27GHfvn3cddddpKWlUVRUxG9/+1vGjx8PGOPtXn75ZRwOB2FhYaxatYrY2Fg2bNhAeHg4TqeT9u3bs3HjRqqzfsngwYMZPHgwu3fvprRXferUqWX5Sqki4L7y+ymlPgc+v+gTaS6M3QZpP5pe3Ro4sctID74aOg2DdrdCdH/wa1yXVrqdBuHxVcbx48fZsGED3t7e5OTksH79eiwWC6tXr+bll1/m88/P/47t2bOH7777jtzcXGJjY3nyySfx8TnXk/vpp59Y9t0mQsKbM+6+29m5dRPx8fE8/vjjrFu3jjZt2jBy5MhK7VqwYAEjR45k2LBhvPzyy5SUlODj48PEiRO58cYbWbx4MQ6Hg7y8PHbt2sWf/vQnNmzYQFhYGKdOXdgB2r59O7/++itt2hhx/ubMmUNoaCiFhYUkJCRw77334nQ6GTduXJm9p06dwsvLi1GjRjF//nwmTZrE6tWr6datW7VET1MPOHPY8OiSV0PK92DLAy8faNkXbp1qeHXNOoEHjyCqceGrrmdWm9x22214exuDh7Ozsxk9ejTJycmICCUlJRXuc8cdd+Dr64uvry/NmjXj+PHjREaenV9b4nAS170nYc2vonVYID179CA1NZWgoCCio6PLxGbkyJHMmjXrvOPbbDaWL1/O3/72N4KDg+nTpw9ff/01Q4YM4dtvv2Xu3LkAeHt707hxY+bOnct9991HWJjRexYaeuH2lt69e5fZAfD222+zePFiANLS0khOTiYzM5MbbrihrFzpcceOHcuwYcOYNGkSc+bM4ZFHHrng+TR1jL0YDv1gCN3+1ZC110hvHAVd7jO8ujY3gG9w3dpZj2jQHp+/v3/Z9quvvsqAAQNYvHgxqamp9O/fv8J9fH19y7a9vb2x2+1ln212B0fPFOLj40ubsEACfC3nlbkQX3/9NWfOnKFLly4AFBQU4O/vz5AhQ6p1bRaLBafTCRhthjabrSwvMDCwbHvt2rWsXr2ajRs3EhAQQP/+/SkqKqr0uFFRUTRv3pxvv/2WzZs3M3/+/GrZpXETpw4aVdfkVZC6HkoKwNsKra6Fng8bYhfW3qO9uqpo2C2YLmRnZ5cNq/joo48u6RgHM/NxKEWA1ZsA33N/M2JjYzl48CCpqakAfPrppxUeY8GCBcyePZvU1FRSU1NJSUlh1apVFBQUcPPNNzNz5kzAmPqVnZ3NTTfdxGeffcbJkycByqq6rVu3Ztu2bQAsW7asUg82OzubkJAQAgIC2LNnDz/++CMAffv2Zd26daSkpJxzXIDHHnuMUaNGcd9995V5zJo6pqTQELkVL8LbPeHtHrD8ecO76/4g/GYhvJgKDy+Bfk9BeKwWvSrwGOF74YUX+P3vf0+PHj2q5aEBFJc4cCpwKMXVjf3x9jr/hfL39+fdd99l0KBB9OrVi+DgYBo3PrfBuKCggJUrV3LHHXeUpQUGBnLdddfxxRdf8M9//pPvvvuOLl260KtXL5KSkoiLi+MPf/gDN954I926dePZZ58FYNy4cXz//fd069aNjRs3nuPluTJo0CDsdjsdO3bkpZdeom9fY6G68PBwZs2axT333EO3bt144IEHyvYZOnQoeXl5uppblygFWfvhx5kw7x74S2uYPxy2fQSh0TDoL/D0dpi4A+6YDu0HgrXid0BzPjUSpGDnzp2p3bp1y6oBe2qUpKSkXuXmiFab4hIHB7PyUUrRJiwQf2vlrQN5eXkEBQWhlGLChAm0a9eOZ5555rLOXxds3bqVZ555hvXrK5wtdtG49uqWUhuT1xtMkAJbPqSsN8bUJa+CM4eM9KYxEHOr0SnR+lrw8a/6OPUAjwhS0FApKnGQkpWPUtAmPAh/n6qrfe+//z4ff/wxNpuNHj168Pjjj7vJ0ppj2rRpzJw5U7ftuQOlIHOvIXT7V8OhDeCwgU+A0RnR72lD7EL1Knw1jfb4KqGoxMHBzHwAosMD8buA6GnOR3t8FVCUAynrTLFbA9nmIIjwDmfnwLbqBxbfqo9Tz9EenwunTp1qlJ6e3hIgNDQ0KzIy8phrflFRkTUlJaW1w+GwKKWIiIjICA0NzQbIy8vzP3ToUCun0+kNqE6dOu329vaulcnpZaInEB2mRU9zGSgFx3ednS1xeCM47WANMgYOX/+cMTWsiY4w407cJnxKKdLT01u2a9dun6+vb0lSUlLHkJCQM4GBgWVjK44cOXJVkyZNTl911VWZ+fn5fvv3728XGhr6i9PpJCUlpU2bNm1SgoKCCktKSrxrKxpMoc2o3opAGy16mkuh8IwxHazUq8s9aqQ37wzXTDDa66L6gKXyOeSa2sVtwpebmxtotVqL/f39bQBNmjQ5dfr06SaBgYHneH0Oh8O79L+Pj08JwJkzZxr7+/sXBgUFFQL4+Pg4asPGQpudg1n5eIkQHRaIrxY9zcXgdMKxn896dWmbQTnAtzG07W92TNwMja6ua0s1Jm4TPpvNZvXx8SkbZWu1Wm35+flBrmUiIiKO7Nu3r11WVlYzp9Pp1a5du30ARUVFvgB79uxpZ7fbLSEhIaciIiKOV3SeY8eOhWVlZYUDZQN8L4YCm52UrHy8RWgTHoivRYuepgoKThmhm/avMcQu/4SR3qIrXDfJELvIBPDW/Yf1kXo1ju/kyZOhoaGhJ7t37/5zTExMcmpqahulFEopyc/PD2rbtm1Kx44d9545cybkzJkzZfNv+vTp0/7zzz9vBNCiRYuszp077/7Pf/5z8s9//nOl5+rfvz+lDeIDB93OzgMZeIsQ7SJ6U6ZMYfr06VXavGTJEpKSkso+T548mdWrV1/GXTiXSZMmERERUS0R19QCTiekb4O1f4HZt8Bf28Lnj8K+FdDmerhrJjy3D55Yb0Q5aXWNFr16jNuejNVqtZWUlJQ1apT3AAFOnjwZVurlNWrUKN/pdHqVlJRYrFarLTAwMNfHx8du5mXn5+cHNGnSJBfgvvvuO7VgwYLQe++9tyxS7+effx763HPPXdCu/GI7f/sgEW9vo3prraant2TJEoYMGVK2poRrFJLLpSGHr7oiKAu3vhoOrDkbbv3qHnDD7wyvLqIneOnawZVGzb/tSyZEcSLpvLBUwUBksSPQ+b1XBxFRITZHgJ+PVxEiZdMb2pY4fbz+K+3xFrtDKa+2NqePzybvtk3DOxYeb/c//g6Hw0tEnHl5ecHNmzcvq+o+9NBDp//85z9HFBUViZ+fn9q7d6/1xIkTPr169eLJJ59ky5YtFBYWMnz4cP74xz+W2VRoVm8H9u3Kli1bsFoa8cYbb/Dxxx/TrFkzoqKi6NWrF2CM0Zs1axY2m42YmBjmzZvHjh07WLZsGd9//z1/+tOf+Pzzz3n99dfLwkWtWbOG559/HrvdTkJCAjNnzsTX15fWrVszevRovvjiC0pKSvjss8/o0KHDebeyoYevqnecE259tbGgDgoCmkLbm435r1dwuHXNWdz2My+An49XUUGJMwDAx0tKvEWcxXan1ctLHD5e4vC1SHFRidOvxIEVs7wAIqKaNWt2PCkpqSMYHl/pMBeA5s2bO7p165a/aNGixqNGjTrz8ccfh955552nRaT5G2+8QWhoKA6Hg5tvvpmff/6Zrl274nAqjpwpolm0Fz7egtXixbZt20hMTGTHjh3Y7XZ69uxZJnz33HMP48aNA+CVV17hgw8+4Omnn2bo0KHnCEspRUVFjBkzhjVr1tC+fXsefvhhZs6cyaRJkwAICwtj+/btvPvuu0yfPp3Zs2efd890+Co3kHvc8OaSV1USbv1muKpHgw/M6WnUvPDd9U6lYaksQFC5NNdhmt5AZbMNmwHNmjWr9Nt8//33n/r0009DRo0adeY///lPwPhQNQAABvtJREFU6Pvvv58KNF+4cCGzZs3Cbrdz9OhRkpKSiG7fkaISB95eRpteKevXr+fuu+8mIMBwWIcOHVqW9+uvv/LKK6/w/+3df2hVZRjA8e9zTZsNWSMLhhs5Sbc0HZtbav6CCqZCiqZ58w8dOmIl/dMfMpHEMtBSCiIlotL0D7VCLhs0f4BZSHM6JM0fLKcozpyt2exazvbj7Y9zvHN3u3Zr995z7znPBw7cvefs3ufsxcdz3vee521ra+PWrVuUlpZGCgWAhoYGcnNzGTNmDADLli1jy5YtocS3YMECACZOnMjevXv7/L6Wr4qTrk5oOtZzVdd8ympPfwzy5sDo511bbl31cM3AzpIlS9rWrFmTc+TIkYfa29t906dP/+vAgQNs3ryZ48ePk5mZSVlZGW3BP7nU+hc+EbIzhzJ4UHT/k5eVlREIBCgoKGD79u0cPnx4QPHeLX8VqayVlq+KoT9+sQtzHoSL38Gdmz3l1p9907qF9UC5ddXDNT2dkZHRPWXKlGB5efnI+fPn3wCraEB6ejoZGRlcv36db2pq+O3WHYY84CNt8CAeCEt6M2bMIBAIcPv2bYLBINXV1aF9wWCQrKwsOjo6ev0jHzZsGMFgsE88eXl5XLp0icbGRgB27tzJzJkzoz6fVC5ftW/fPvLy8igtLWXjxo19PktEHhSRPSLSKCJ1IjLynn2r7fYGEbn/ZXUknX9bj4UdXAtbn4H3n4Sq16GpHsbOhZd2wKqLsLzGWhM2q0CTnse4qrf9fv+NhoaGoUuXLr0BkJ+fT2FhIfn5+Sz2v8yEoqcZ7PMxanh6v6XKioqKWLx4MQUFBcyePZuSkpLQvvXr1zNp0iSmTp3aayLC7/ezadMmCgsLuXDhQqg9LS2Nbdu2sWjRIsaPH4/P56OioiKq80jl8lVdXV2sXLmSmpoaqqur2bVrV6+v+9hWAL8bY54APgDeBRCRsVgLD40DZgFbReS/TZkeegfey4UvXoDardYt6/Nvwas/wBtnYd5H1loTQx/+T2+r3MUzRQraO7q4drOdnMyhfa701P/TX/mq2tpa1q1bx/79+zl37hyBQACA1atXA9bD60ArsM4YU2uvq9sMPApUAhhjNtjH7r973P3i6FWkoH4bXDtpPew/aqaWW3eIFilIEmmDB5E7XAs1xkqk8lVXr14lJycn9HN2djZ1dXXhvz4CuAJgjOkUkZvAI3b70XuOa7LbolecIpMsylF66aP+l8rKSi5fvsy0adMc+XwReUVE6kWkvqWlxZEYVOqKVeLr7u7u1gL/ihEjRnDlyhXuDqE0NTWF1jq5x1UgB8C+1c3Auv0Ntduy7bY+jDGfGGOKjTHFKfn9QeWoWCW+0y0tLRma/FRJSQnnz5/nxIkT+Hw+du/e3ev7kLYqYJn9eiFwyFiZsgrw27O+ucBo4FjCgleeEZMxvs7OzvLm5uZPm5ubnyKJbp9bW1sRXWkq4VatWsXChQvx+XwsX76ccePGsXbtWoqLQ2PdnwE7RaQRuIE1k4sx5oyIfAmcBTqBlcaYuJQgU94Wk1ndZJVSJck9wvOl5z0i2Wd1k+bqTCmlEkUTn1LKczTxKaU8x9VjfCLSAly+p2k4kHRPmEQpVWMPj/txY0xMv3/ion52U9wx7+dYcnXiCyci9ck84Ho/qRq7E3Hr3yqxUjFuvdVVSnmOJj6llOd4LfF94nQAA5CqsTsRt/6tEivl4vbUGJ9SSoH3rviUUkoTn1LKe1yZ+ERklr1mQ6OIVPazP+KaD06KIu4yEWkRkR/trdyJOMOJyOci8quInI6wX0TkQ/u8TolIUYw+V/s5gZzq57gwxrhqw1ql8gIwChgCnATGhh3zGvCx/doP7EmRuMuAj5yOtZ/YZwBFwOkI++cANVjLK08G6rSftZ+d3Nx4xfc00GiMuWiM+RvYDcwLO2Ye8IX9+mvgOXG+flU0cSclY8z3WOWlIpkH7DCWo8DDIpI1wI/Vfk4wh/o5LtyY+ELrOdj6W7eh15oPwN01H5wUTdwAL9q3EV+LSE4/+5NRtOcW6/fUfk6sePRzXLgx8blZNTDSGDMBOEjP1YxyF+3nOHNj4otm3YZIaz446V/jNsa0GmPu2D9+CkxMUGwDFfVaGjF+T+3nxIpHP8eFGxPfcWC0iOSKyBCsQe2qsGMirfngpH+NO2y8ZC5wLoHxDUQVsNSe9ZsM3DTGXBvge2o/J5949HN8OD27Eo8Na3bpZ6zZszV229vAXPt1GvAV0Ii1mM0op2OOMu4NwBmsmcBvgXynY7bj2gVcAzqwxnVWABVAhb1fgC32ef0EFGs/az87uekja0opz3Hjra5SSt2XJj6llOdo4lNKeY4mPqWU52jiU0p5jiY+pZTnaOJTSnnOP+BImt56AucKAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 288x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX2Ck-a64bTJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8deb4b2-658c-4cfd-fe9a-77c39814df98"
      },
      "source": [
        "print(cat_test[0:3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['10291.jpg', '8982.jpg', '4178.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzdLrHe7EirZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52f6569e-5fd3-46f4-90a4-dbd5b41bca74"
      },
      "source": [
        "print(dog_test[2:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['4178.jpg', '4147.jpg', '7340.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDpiYUN5-3QI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "98cd6716-c8e8-49fb-bbd7-6b543e583092"
      },
      "source": [
        "# summarize feature map size for each conv layer\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from matplotlib import pyplot\n",
        "# load the model\n",
        "model = VGG16()\n",
        "# summarize feature map shapes\n",
        "for i in range(len(model.layers)):\n",
        "\tlayer = model.layers[i]\n",
        "\t# check for convolutional layer\n",
        "\tif 'conv' not in layer.name:\n",
        "\t\tcontinue\n",
        "\t# summarize output shape\n",
        "\tprint(i, layer.name, layer.output.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 block1_conv1 (None, 224, 224, 64)\n",
            "2 block1_conv2 (None, 224, 224, 64)\n",
            "4 block2_conv1 (None, 112, 112, 128)\n",
            "5 block2_conv2 (None, 112, 112, 128)\n",
            "7 block3_conv1 (None, 56, 56, 256)\n",
            "8 block3_conv2 (None, 56, 56, 256)\n",
            "9 block3_conv3 (None, 56, 56, 256)\n",
            "11 block4_conv1 (None, 28, 28, 512)\n",
            "12 block4_conv2 (None, 28, 28, 512)\n",
            "13 block4_conv3 (None, 28, 28, 512)\n",
            "15 block5_conv1 (None, 14, 14, 512)\n",
            "16 block5_conv2 (None, 14, 14, 512)\n",
            "17 block5_conv3 (None, 14, 14, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPL1UJj1CgeK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9a000365-e606-4944-a2e4-3bc1a4301909"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "from tensorflow.keras import preprocessing\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import models\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "image_size = 224\n",
        "\n",
        "# Load pre-trained Keras model and the image to classify\n",
        "model = tf.keras.applications.vgg16.VGG16()\n",
        "image = np.random.random((image_size, image_size, 3))\n",
        "img_tensor = preprocessing.image.img_to_array(image)\n",
        "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "img_tensor = preprocess_input(img_tensor)\n",
        "\n",
        "conv_layer = model.get_layer(\"block5_conv3\")\n",
        "heatmap_model = models.Model([model.inputs], [conv_layer.output, model.output])\n",
        "\n",
        "# Get gradient of the winner class w.r.t. the output of the (last) conv. layer\n",
        "with tf.GradientTape() as gtape:\n",
        "    conv_output, predictions = heatmap_model(img_tensor)\n",
        "    loss = predictions[:, np.argmax(predictions[0])]\n",
        "    grads = gtape.gradient(loss, conv_output)\n",
        "    pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_output), axis=-1)\n",
        "heatmap = np.maximum(heatmap, 0)\n",
        "max_heat = np.max(heatmap)\n",
        "if max_heat == 0:\n",
        "    max_heat = 1e-10\n",
        "heatmap /= max_heat\n",
        "\n",
        "print(heatmap.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 14, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw3vgeJVISn4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}